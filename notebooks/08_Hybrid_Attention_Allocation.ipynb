{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53846939-5e4b-4889-9f4d-3b92e466e756",
   "metadata": {},
   "source": [
    "# 08 - Hybrid Attention-Based Allocation\n",
    "This notebook builds on the hybrid strategy logic and integrates interpretability insights from the ATT-LSTM model.\n",
    "The aim is to:\n",
    "\n",
    "- Identify if attention weights can inform capital allocation\n",
    "- Show how interpretability from AI models can enhance investment strategies\n",
    "- Lay the groundwork for future adaptive allocation via explainable AI (XAI)\n",
    "\n",
    "\n",
    "\n",
    "## ðŸŽ¯ Slide 8 â€“ Hybrid Attention-Weighted Strategy\n",
    "\n",
    "This strategy combines ATT-LSTM predictions with attention-based position sizing. By trading only when attention weights are high, and sizing positions dynamically, it aims to improve interpretability and stability.\n",
    "\n",
    "We use:\n",
    "- Binary signals from ATT-LSTM\n",
    "- Filtering using attention scores\n",
    "- Dynamic position sizing proportional to attention\n",
    "\n",
    "This creates a confidence-aware, interpretable AI strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68751a39-a763-470a-a97d-4225197172ef",
   "metadata": {},
   "source": [
    "## 1. Imports and Data Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e49360-e912-416a-8375-2e7cf13b7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import vectorbt as vbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61710a7d-4b50-4b06-b75a-5c837058aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed predictions (make sure index is datetime)\n",
    "att_df = pd.read_csv(\"../data/df_att_with_attention.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Load SPY historical prices\n",
    "df_spy = pd.read_csv(\"../data/GSPC_fixed.csv\", parse_dates=['Date'], index_col='Date')\n",
    "df_spy = df_spy[['Adjusted_close']].rename(columns={'Adjusted_close': 'SPY'})\n",
    "\n",
    "# Align SPY to match att_df date index (business days, holidays included)\n",
    "df_spy = df_spy.reindex(att_df.index).ffill()  # forward fill to avoid NaNs on missing market holidays\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf816517-85fd-4102-8145-12e0e6cc4835",
   "metadata": {},
   "source": [
    "## 2. Signal Generation from Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2b0d7-7014-4b29-b170-9f7ca61e15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Signal Generation ===\n",
    "\n",
    "# Create binary signal from predictions\n",
    "att_df['signal'] = (att_df['predictions'] > 0.5).astype(int)\n",
    "\n",
    "# Optional: store raw copies for experimentation\n",
    "att_df['raw_signal'] = att_df['signal']  # Backup signal\n",
    "att_df['raw_attention'] = att_df['attention_mean']  # Backup attention weights\n",
    "\n",
    "# Preview\n",
    "att_df[['predictions', 'signal', 'attention_mean']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76cfaf-547f-4c2a-832c-53c758010f8b",
   "metadata": {},
   "source": [
    "## 3. Attention-Based Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2b1c2-cac7-464b-a61e-311a6a27fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(att_df.index, att_df['attention_mean'], label='Attention Score', color='crimson')\n",
    "plt.title(\"ATT-LSTM Attention Weights Over Time\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Attention Weight\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"1_att_lstm_attention_scores.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e11e15-e904-41da-9f7d-31fcfbe15aef",
   "metadata": {},
   "source": [
    "## 4: Attention-Enhanced Allocation Strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2a1ac-0437-4584-8bf6-46480e01b5fd",
   "metadata": {},
   "source": [
    "### 4.1: Attention-Based Signal Filtering\n",
    "Only trade if the model is confident (i.e., attention weight exceeds a threshold)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "df4d7d14-0474-4ab7-a01d-68dbce92b0df",
   "metadata": {},
   "source": [
    "# === 4.1 Attention-Based Signal Filtering ===\n",
    "# Only allow trades when the attention weight is high enough (confidence threshold)\n",
    "att_df['filtered_signal'] = np.where(att_df['attention_mean'] > 0.15, att_df['signal'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc92b1d-632b-4cb5-be22-c5eae0eae042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Skip filtering temporarily\n",
    "att_df['filtered_signal'] = att_df['signal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d7eeb-1575-46cd-aeac-503f00890375",
   "metadata": {},
   "source": [
    "### 4.2: Attention-Based Position Sizing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3efb89cf-3ba1-4ed7-8d02-1e12865003fb",
   "metadata": {},
   "source": [
    "# === 4.2 Attention-Based Position Sizing ===\n",
    "# Multiply confidence (attention) by signal to produce fractional position size\n",
    "att_df['size'] = att_df['filtered_signal'] * att_df['attention_mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c11a93-b01e-4d0b-8cc2-9e03770e39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use attention for sizing\n",
    "att_df['size'] = att_df['filtered_signal'] * att_df['attention_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c4966-7ae7-43f6-84ee-7fe0d15f61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df['size'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2699fa4-a9be-4089-af11-0c62ba2d4b48",
   "metadata": {},
   "source": [
    "### 4.3: Backtest Attention-Based Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa284ff-a056-46de-b040-87676803ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4.3 Backtest with Attention-Based Allocation ===\n",
    "import vectorbt as vbt\n",
    "\n",
    "pf_att_alloc = vbt.Portfolio.from_signals(\n",
    "    close=df_spy['SPY'],\n",
    "    entries=att_df['filtered_signal'] == 1,\n",
    "    exits=att_df['filtered_signal'] == 0,\n",
    "    size=att_df['size'],  # fractional sizing\n",
    "    freq='1D',\n",
    "    init_cash=100,\n",
    "    fees=0.001\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44594552-ba73-4934-91d4-6cb974bc4be0",
   "metadata": {},
   "source": [
    "### 4.4: Visualize the Strategy vs Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35148d5d-0333-4ff4-8ad9-25383cd67a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(pf_att_alloc.value(), label='ATT-LSTM + Attention Allocation', linewidth=2)\n",
    "plt.plot((df_spy['SPY'] / df_spy['SPY'].iloc[0]) * 100, label='SPY Buy & Hold', linestyle='--')\n",
    "plt.title(\"Performance: Attention-Weighted Strategy vs SPY\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value (Base 100)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"2_attention_strategy_vs_spy.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62edc2d2-2b8b-4d90-b1f7-a71c93cf1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df['filtered_signal'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a588588-9ce3-417d-b7c0-924306428f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df['size'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a6512-d85b-4983-b2b8-2bbf16ae18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_att_alloc.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf53cd-3e89-4658-a114-5bad985352d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df['signal'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259c96b-3a10-4858-8d1f-d1dc0c30989c",
   "metadata": {},
   "source": [
    "### Plot: Position Size Over Time\n",
    "Show how attention affects exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3a5dd-f5fc-4c14-a46e-2b6dc8abb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(att_df.index, att_df['size'], label='Position Size (Attention-Weighted)', color='teal')\n",
    "plt.title(\"Position Size Over Time (Driven by Attention)\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Fractional Position Size\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"3_attention_position_size.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b807d4-0a3c-428a-a1d0-745bdaf40161",
   "metadata": {},
   "source": [
    "### Stats Summary\n",
    "Get portfolio stats (trades, drawdown, Sharpe, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92696d-e920-4bac-9f5d-995ae6822ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_stats = pf_att_alloc.stats()\n",
    "print(pf_stats[['Total Trades', 'Total Return [%]', 'Max Drawdown [%]', 'Sharpe Ratio']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658e74e-9ead-4e6b-8173-af4ef762cf6c",
   "metadata": {},
   "source": [
    "### Plot: Rolling Sharpe\n",
    "To show consistency of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4535a-e7f3-4e01-bf69-81dc61073f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 3-month rolling Sharpe Ratio manually (63 trading days)\n",
    "rolling_returns = pf_att_alloc.daily_returns()\n",
    "rolling_sharpe = rolling_returns.rolling(window=63).mean() / rolling_returns.rolling(window=63).std()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(rolling_sharpe, color='purple', label='3-Month Rolling Sharpe')\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "plt.title(\"Rolling 3-Month Sharpe Ratio (Attention Strategy)\", fontsize=14)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sharpe Ratio\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"4_rolling_sharpe_attention.png\", dpi=150)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de970c-997a-43fc-b143-27f53f27729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_returns = pf_att_alloc.daily_returns()\n",
    "sharpe_raw = rolling_returns.rolling(window=63).mean() / rolling_returns.rolling(window=63).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f13783-1a1a-47b7-ad6d-b5d4fd9882a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_annualized = sharpe_raw * np.sqrt(252)  # annualize for daily frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271bdddb-26c8-4302-af01-d8d55a7a6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(sharpe_raw, label='Raw 3-Month Sharpe', linestyle='--', color='gray')\n",
    "plt.plot(sharpe_annualized, label='Annualized 3-Month Sharpe', color='purple')\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "plt.title(\"Rolling 3-Month Sharpe Ratio: Raw vs Annualized\", fontsize=14)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sharpe Ratio\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"5_rolling_sharpe_comparison.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
